- The EAT repository is derived from [SphereFormer](https://github.com/dvlab-research/SphereFormer). See their setup to get this project up and running.
- [Download the trained model](https://drive.google.com/file/d/1GauUHjrEQu6LMY1YlunbB0UJ77hXb33J/view?usp=sharing) and put it somewhere in the project. Adjust the ```resume``` path in ```config/semantic_kitti/semantic_kitti_unet32_spherical_transformer_SSC_sparse_hybrid_unet_expanding_attn_convlike_EATv2_inner_expansion_test_NO_conv_spatial_embs``` accordingly.
- Run ```CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python train.py --config ~/thesis/EAT/config/semantic_kitti/semantic_kitti_unet32_spherical_transformer_SSC_sparse_hybrid_unet_expanding_attn_convlike_EATv2_inner_expansion_test_NO_conv_spatial_embs.yaml```. We used 6 GPUs. If you use less, you have to adjust the ```batch_size``` in the config accordingly. 
